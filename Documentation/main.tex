%You should submit:

    %Functional source code, in a public github repository,

    %A 4-page summary, which should focus on the technical part: the algorithms, their implementation, and their performance.

    %Material for the oral presentation (slides), which should focus on the process: what decisions were taken and why, which strengths/shortcomings were found, and a critical discussions of the results.

%https://en.wikibooks.org/wiki/LaTeX/Document_Structure
\documentclass[11pt]{article}
\usepackage{blindtext}
\usepackage{titlesec}
\setcounter{tocdepth}{3}
%\documentclass[10pt,twoside,a4paper]{article}
\usepackage{graphicx}
\usepackage[a4paper]{geometry}
\usepackage{subcaption}
\usepackage{comment}
\geometry{verbose,tmargin=3cm, hmargin=2cm}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage[section]{placeins}
\usepackage{xparse}
\usepackage{csvsimple, booktabs}

\usepackage[toc]{appendix}
\usepackage{mwe}
\usepackage{float} % Figure placement "Here".

\usepackage{appendix}

\usepackage{fancyhdr} % headers and footers
\pagestyle{fancy}

\usepackage{afterpage}

% thanks
% https://tex.stackexchange.com/questions/11366/how-can-i-get-the-figures-not-to-be-pushed-to-the-end-of-the-document
\renewcommand{\topfraction}{.85}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\textfraction}{.15}
\renewcommand{\floatpagefraction}{.66}
\renewcommand{\dbltopfraction}{.66}
\renewcommand{\dblfloatpagefraction}{.66}
\setcounter{topnumber}{9}
\setcounter{bottomnumber}{9}
\setcounter{totalnumber}{20}
\setcounter{dbltopnumber}{9}

\NewDocumentCommand{\codeword}{v}{%
\texttt{\textcolor{black}{#1}}%
}

\lstset{language=Python,keywordstyle={\bfseries \color{blue}}}

\begin{document}

\title{A simple detector for crowd counting using OpenCV and Python}
\author{Martí Gelabert Gómez}
\date{\today}
\maketitle

\tableofcontents
\section{Introduction}
The assignment consists in \textbf{counting} the number of people that appear on the given images. There was not an stablished way to aproach this problem. In this case I have taken the decision of using the computer vision algorithms seen in class and not relay on deep learning or any kind of artificial inteligence algorithm. This is because not by de amount of data needed for training, due to there are really god datasets out there, like MS COCO, but because of the effort of building a good performing detector architecture. Use an already set framework as YOLO or Mask-RCNN would be the way to accomplish the task, but I would be thinking about it as "cheating". Therefore, this way, using the content seen in class, I will be more cautious about my decisions and It will be much easier to justify them.\\

In the following document  we will be focusing on the process taken and the algorithms used, their implementation and their performance.        

\section{General Procedure}
The program takes the following steps :

\begin{enumerate}
    \item Import images as black and white.
    \item Apply Adaptative Histogram equalization to the images.
    %\item Generate an image from the averaging from all the images we have with the Histogram equalization already applyed.
    \item Substract the background to the images using the image with the background.
    %\item Apply an erosion algorithm to obtain small highlighted areas.
    \item Apply a thresholding algorithm to binarize the image.
    \item Apply a dilation operation into the binarized images to expand the whites.
    \item Use a contour algorithm to extract the diferent regions containing persons.
    \item Obtain the bounding boxes from these regions.
    \item Count them and compare the number of detections to the real cuantity.
    \end{enumerate}
    
\section{algorithms}
In this section we will discuss the algorithms selected and the output we obtain from them in the application of our problem.

% Check spell
\subsection{Background Removal} 
Background removal is a technique that allows to remove the background from the image, this way, the output will be only the foreground highlighted in the form of a binarized image as it can be ilustrated on the figure \ref{fig: img_reference}. 

\begin{figure}[h]
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/bin_ex.jpg}
        \caption{Output of background substraction using cv2.threshold(image, 100, 255, cv2.THRESH\_BINARY)}
        \label{fig:y equals x}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/or_ex.jpg}
        \caption{Original 1660320000.jpg}
        \label{fig:y equals x}
    \end{subfigure}

    \caption{Reference images}
    \label{fig: img_reference}
\end{figure}

In the following sections will be explained how the preprocessing of this technique was prepared and for what they are used for. They are ordered by    

\subsubsection*{CLAHE}

In the case of our problem, first we have imported all the images in black and white integer values using \codeword{cv2.imread(img,0)}. Then for a better extraction, it has been applyed an \textbf{algorithm of CLAHE} seen previously on the course to try to uniformize the ilumination of the images. With a more uniform images, we will be able to distinguish more precisely our foreground and artifact like shadows casted by objects on the images may have less impact on the \textbf{binarization process}.

\begin{figure}[h]
    \centering % <-- added
\begin{subfigure}{0.25\textwidth}
  \includegraphics[width=\linewidth]{img/equ/1660284000.jpg}
  \caption{1660284000.jpg with CLAHE applyed}
  \label{fig:1}
\end{subfigure}\hfil % <-- added
\begin{subfigure}{0.25\textwidth}
  \includegraphics[width=\linewidth]{img/equ/1660287600.jpg}
  \caption{1660287600.jpg with CLAHE applyed}
  \label{fig:2}
\end{subfigure}\hfil % <-- added
\begin{subfigure}{0.25\textwidth}
  \includegraphics[width=\linewidth]{img/equ/1660302000.jpg}
  \caption{1660302000.jpg with CLAHE applyed}
  \label{fig:3}
\end{subfigure}

\medskip
\begin{subfigure}{0.25\textwidth}
  \includegraphics[width=\linewidth]{../gen/gray/1660284000.jpg}
  \caption{1660284000.jpg gray}
  \label{fig:4}
\end{subfigure}\hfil % <-- added
~
\begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{../gen/gray/1660287600.jpg}
    \caption{1660287600.jpg gray}
    \label{fig:4}
  \end{subfigure}\hfil % <-- added
~
  \begin{subfigure}{0.25\textwidth}
    \includegraphics[width=\linewidth]{../gen/gray/1660302000.jpg}
    \caption{1660302000.jpg gray}
    \label{fig:4}
  \end{subfigure}\hfil % <-- added
  \caption{Images from Gelabert folder where the first row presents a more uniform ilumination across frames ompared with the second row images.}
\end{figure}

\FloatBarrier
\subsubsection*{Background Image}

For the selection of our background image, in a starting point the \textbf{average image} was computed as the main way for accomplish foreground extraction, but the resulting image generally was really noisy and with ghosting effect very present on it, which decreased the performance of the algorithm as it can bee seen on the Figure \ref{fig:avg}. Even with a gaussian blur applyed to try to counter the ghosty figures, they are still really present on the image. The image averaging is a good idea generally for noise reduction and in this case to try to obtain a neutral image were the background is predominant, but there is not enought images to obtain a more sharp image to really have a good background. Therefore, we \textbf{end up} using the image 1660284000.jpg with a gaussian blur applyed as our background, this way we obtain better results on the \textbf{binarization process}.

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.9\textwidth]{img/avg.png}
%    \caption{Average image with a gaussian blur applyed with a kernel of (11,11)}
%    \label{fig:avg}
%\end{figure}



\subsubsection*{Gaussian Blur}
With an image already selected for the image background, it is applyed a gaussian filtering with a kernel of size (7,7), this way  we can obtain a more standard image, and get a more smuthered image that will allow the algorithm to contrast slightly better our foreground.\newline

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.9\textwidth]{img/back_blur.png}
%    \caption{Gaussian Blur Applyed with a kernel of size (7,7)}
%    \label{fig:gaussian}
%\end{figure}



The ending size used for gaussian blur was obtained by trial and error experimentation, and could be changed to get different ending behaveours.


\subsubsection*{Substraction}

Once we have selected our background and applyed the preprocessing, we should substract it to every image, this way, the result we end up with is the foreground (in this case the persons and some residuals) highlighted as we can see in the figure \ref{fig:sub}. 

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{img/sub.jpg}
%    \caption{Image obtained by applying cv2.subtract(background, image)}
%    \label{fig:sub}
%\end{figure}


\subsection{Binarization}
Once the substraction has been aplyed to all images, the resulting foreground will contain hopefully our persons. All those whity areas should be further treated using a binarization progress, allowing a solid division between  the background and our foreground. This is acomplish by the process of binaryzation. Depending of the process selected, the resulting image will transform into a binary black and white image from a gray scale one. In this assignment there has been some experimentation using OTSU and the binary threasholding function avaliable on cv2 library, but for the sake of the performance, the last one has been ultimately selected.\newline

The problem with using OTSU is that for each images it obtains a threshold selection automatically, and this should not be a problem, and sometimes could perform better than a fixed one. But for the samples tested there are a lot of artifacts related to the shadow casting of the image, as it can be seen in the figure \ref{fig:otsu_bin}. The problems are seen on the bottom of the image, where there are an amount of shadows casted by the sand crests which can be a bit annoying for the next steps.\newline


%\begin{figure}[h]
%    \centering
%    \includegraphics[width=\textwidth]{img/OTSU_sub_arena.jpg}
%    \caption{Binarized image using OTSU and the empty beach image}
%    \label{fig:otsu_bin}
%\end{figure}

%\FloatBarrier


By using a set thresholding we are loosing some flexibility and a fixed values could not be the wiser idea, but in this case using a tigth threshold may be the best decision as may reduce the number of false detections considerably. In this case the values selected are setted in the instruction \codeword{cv2.threshold(substracted, 100, 255, cv2.THRESH_BINARY)}. The resulting image can be shown in figure \ref{fig:binth}.


%\begin{figure} [hp]
%    \centering
%    \includegraphics[width=\textwidth]{img/bin_th.jpg}
%    \caption{Binarized image using a fix thresholding method}
%    \label{fig:binth}
%\end{figure}

\subsubsection*{Masking}
For a better filtrage of our data, we will be using a binary mask to get rid of centain areas of the image where we can get non-persons in the foreground (i.e the quay part) and those areas where there is to much information to get clear data about it. We can see the last case in the umbrella section of the beach and the pavement area, where there are too many persons overlaping each others. The mask applyed can be seen in the figure \ref{fig:mask_ex}.



\subsection{Dilation}
Now, with the image binarized we will a apply a dilation to the image. The dilation will expand the white color on a binarized image, obtaining as results the highlighted areas in form of white chunks as it can be seen on figure \ref{fig:dilation_ex}. With these chunks the countourn detection will obtain better results because they are more clear shapes. This could merge figures into one, so the parameters of the kernel size may be tinkered with to obtain the best performance possible.



\subsection{Find contours}
Once a binarized image is obtained, there should be a process of contour detection. Here we use the dilated images over the function that openCV provides \codeword{cv2.findContours()}. From this functions, we can extract the bounding boxes that contain each of the object contours. In the figure \ref{fig:detections} appears the image with some bounding boxes applyed.


\subsection{Matching Algorithm}
For convenience, we will cuantify our detection accuracy using the some "incorrect" assumptions. We will be checking if the bounding box contain labels, only one label containing will be assigned to that bounding box. In the case we would have a really big box keeping a lot of detection we will not count that as correct, but in the cases where it may contain a region of 4 or 5 persons because they are really close to each other, we would be more flexibles.\newline

For checking the dimensionality of the bounding box, we would assume that width or height higher than a third of the image will not be acceptable, and the same for the ones no more than two pixels size. 
\section{Results Analysis}

\begin{table} [hp]
    \centering
    \caption[Performance metrics Basic]{Performance metrics using the propossed algorithm}\label{table:metrics}
\csvautobooktabular{../metrics.csv}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{img/det_name.jpg}
    \caption{Output of foreground detector, as it can be seen there are some big detections due to contourn detecting multiple forms as one shape, and some }
    \label{fig:detections}
\end{figure}


\section{Is a different aproach capable of improving our results?}

For some of the test that were executed for this assignment, generally the effort was not useful. The following  


Ending up in situations where a precise modification to the parameters gave as output really good results only in a set of the images. Usually the over-tunning of some function parameters made really inconsisten outputs that provoked a bad performance.  


\subsection*{Color Spacing}
 For example, one of the aproches taken for background removal, was the use of colored images in the color space of LAB  instead of gray scale. On the paper one may think that the use of color will improve our performance, because of the extra information we are just acquired from free. But in this case the process to obtain our foreground sections were in general less precice, giving as result a lot more objects as foreground, which is not ideal for our case, been a lot of those object just umbrellas and cast shadows.\newline

\subsection*{The problem with shadows}

In general, the sample images follow a consisting landscape withouth heavy cast shadows on the sand, but it is noticeable in some of them and usually they will give you more than one headache.\newline 

We could try to counter some of the cases using a sharpening processes or even more filtering (i.e median filtering), to avoid certain annoience for shadows, but doesn't mean that it will be worth it to apply. We could have the situation again where is really useful for 1 case, but then the rest of images just got obliterated just for applying those transformations.



\section{Conclusions}

As we could be expecting, the performance is not really good compared to a neural network. There are some cases where we can be completely sure about classifing incorrectly our detection because of how the ground truth is placed, some detections are actually correct but slightly shifted and withouth a manually intervention it is safer to just leave it as 'incorrect'. In general, the amount of false positives increase in function of which process are used but overall the false positives generally concetrates in distance areas where there is a lot of information compacted and the dock area.\newline

The use of background subtraction to try to extract completely our foreground is a tricky task, because using an averaged image could allow to have an image with the solid background on it, but it works better when we dispose with a lot of images. With just the images from the 'Gelabert' folder the image generated was not clear enought (even with some pprocessing) to accomplish the objective and in the end jsut using the emtyes image was the one given the best performance.\newline


\newpage
\begin{appendices}
    \section{Images related to the basic Algorithm}
    % the \\ insures the section title is centered below the phrase: AppendixA

    

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{img/sub.jpg}
        \caption{Image obtained by applying cv2.subtract(background, image)}
        \label{fig:sub}
    \end{figure}

    \begin{figure} [h]
        \centering
        \includegraphics[width=\textwidth]{img/bin_th.jpg}
        \caption{Binarized image using a fix thresholding method}
        \label{fig:binth}
    \end{figure}
    
    \begin{figure} [h]
        \centering
        \includegraphics[width=\textwidth]{../mask.png}
        \caption{Mask image}
        \label{fig:mask_ex}
    \end{figure}
    
    \begin{figure} [h]
        \centering
        \includegraphics[width=\textwidth]{img/dil.jpg}
        \caption{Dilation applyed to the binarized image}
        \label{fig:dilation_ex}
    \end{figure}
    
    

    \section{Complementary Images}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.9\textwidth]{img/avg.png}
        \caption{Average image with a gaussian blur applyed with a kernel of (11,11)}
        \label{fig:avg}
    \end{figure}

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{img/OTSU_sub_arena.jpg}
        \caption{Binarized image using OTSU and the empty beach image}
        \label{fig:otsu_bin}
    \end{figure}
        
\end{appendices}



\end{document}
